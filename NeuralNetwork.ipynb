
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline

x_data = np.linspace(0, 10 ,10) +np.random.uniform( -1.5 ,  1.5 ,10)
y_lable = np.linspace(0 ,10 ,10 ) + np.random.uniform(-1.5 , 1.5, 10)

plt.plot(x_data , y_lable , '*')

m = tf.Variable(0.42)
b = tf.Variable(0.21)

error = 0
for x,y in zip(x_data , y_lable):
    y_hat = m*x+b # calculated value
    error += (y-y_hat)**2  # error 

optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.001)

train = optimizer.minimize(error)

init = tf.global_variables_initializer()

with tf.Session() as sess:
    sess.run(init)
    training_steps = 100
    
    for i in range(training_steps):
        sess.run(train)
    final_slope , final_intercept = sess.run([m , b])

x_test = np.linspace(-1 ,11 ,10)

# y = mx+c

y_pred_plot = final_slope*x_test + final_intercept

plt.plot(x_test,y_pred_plot,'r')

plt.plot(x_data,y_lable,'*')
